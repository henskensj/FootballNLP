{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langdetect in c:\\users\\hovensa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (1.0.7)\n",
      "Requirement already satisfied: six in c:\\users\\hovensa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from langdetect) (1.11.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\hovensa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\hovensa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from gensim) (1.13.3)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in c:\\users\\hovensa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from gensim) (1.5.7)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\hovensa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from gensim) (0.19.1)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\hovensa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from gensim) (1.11.0)\n",
      "Requirement already satisfied: bz2file in c:\\users\\hovensa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
      "Requirement already satisfied: requests in c:\\users\\hovensa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
      "Requirement already satisfied: boto>=2.32 in c:\\users\\hovensa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from smart-open>=1.2.1->gensim) (2.48.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\hovensa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from smart-open>=1.2.1->gensim) (1.7.4)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\hovensa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\hovensa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\hovensa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hovensa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.2.1->gensim) (2018.4.16)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\hovensa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n",
      "Requirement already satisfied: botocore<1.11.0,>=1.10.4 in c:\\users\\hovensa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.2.1->gensim) (1.10.4)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in c:\\users\\hovensa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.2.1->gensim) (0.1.13)\n",
      "Requirement already satisfied: python-dateutil<2.7.0,>=2.1 in c:\\users\\hovensa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from botocore<1.11.0,>=1.10.4->boto3->smart-open>=1.2.1->gensim) (2.6.1)\n",
      "Requirement already satisfied: docutils>=0.10 in c:\\users\\hovensa\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from botocore<1.11.0,>=1.10.4->boto3->smart-open>=1.2.1->gensim) (0.14)\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n",
      "C:\\Users\\hovensa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['char']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import langdetect\n",
    "import gensim.models\n",
    "from gensim.models import Word2Vec\n",
    "import sys\n",
    "np.random.seed(0)\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "%pylab inline\n",
    "#read tweets\n",
    "folder = \"/Users/hovensa/OneDrive - delaware/Data science/WK/\"\n",
    "#df1 = pd.read_csv(folder + \"#rodeduivels_2018-06-11.csv\", delimiter = ';')\n",
    "#df2 = pd.read_csv(folder + \"#PorBel_2018-06-11.csv\", delimiter = ';')\n",
    "df3 = pd.read_csv(folder + \"#BelPor_2018-06-06.csv\", delimiter = ';')\n",
    "#df4 = pd.read_csv(folder + \"DiablesRouges_2018-06-11.csv\", delimiter = ';')\n",
    "#df5 = pd.read_csv(folder + \"tweetsQuinten-2018-06-11.csv\", delimiter = ';')\n",
    "#df6 = pd.read_csv(folder + \"RSCA_2018-06-11.csv\", delimiter = ';')\n",
    "#df7 = pd.read_csv(folder + \"kaaGentAf_2018-06-11.csv\", delimiter = ';')\n",
    "dfTemp = [df3]#,df2,df3,df4,df5,df6,df7]\n",
    "#df1 = pd.read_csv(folder + \"RSCA_2018-06-06.csv\", delimiter = ';')\n",
    "#dfTemp = [df1]\n",
    "df = pd.concat(dfTemp, ignore_index=\"True\")  \n",
    "df_url = df.text[:].str.replace('http\\S+|www.\\S+', '', case=False)\n",
    "df_RT = df_url.str.replace('RT ','',case=True)\n",
    "df_tags = df_RT.str.replace('(@\\w{0,})', '',case=False)\n",
    "df_hash = df_tags.str.replace('(#\\w{0,})', '',case=False)\n",
    "df_col2 = df_hash.str.replace('FACEBOOK LIVE Q&amp;A: ','',case=False)\n",
    "df_trim = df_col2.str.lstrip()\n",
    "\n",
    "df_final = pd.DataFrame({\"Emotion\":df.Emotion, \"text\": df_trim})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_text = pd.DataFrame(df_final)\n",
    "df_text['Language'] = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index,i in df_text.iterrows():\n",
    "    try: \n",
    "        if langdetect.detect(i.text) == 'af':\n",
    "            i.Language = 'nl'\n",
    "        if langdetect.detect(i.text) != 'nl' and langdetect.detect(i.text) != 'fr':\n",
    "            i.Language = 'NA'\n",
    "        else: \n",
    "            i.Language = langdetect.detect(i.text)\n",
    "    except:\n",
    "        i.Language = 'NA' \n",
    "df_filtered = df_text[df_text['Language'] != 'NA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hovensa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "def DefineEmoticons(language,text):\n",
    "    \n",
    "    emoticondf = pd.read_csv(open(folder + \"emoticons_\"+language+\".txt\",'rt'), delimiter = \"\\t\")\n",
    "    text[\"emotion_\"+language] = \"\"\n",
    "    for index,line in text.iterrows():\n",
    "        for index,row in emoticondf.iterrows():\n",
    "            if(row.Emoticon in line.text): \n",
    "                line[\"emotion_\"+language] = row.Description\n",
    "           \n",
    "    return text\n",
    "\n",
    "text_ad = DefineEmoticons(\"nl\",df_filtered)\n",
    "text_ad = DefineEmoticons(\"en\",text_ad)       \n",
    "text_ad = DefineEmoticons(\"fr\",text_ad)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hovensa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\hovensa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#the addition of an emotion word to the tweet text\n",
    "text_ad['emotion']= ''\n",
    "for index,i in text_ad.iterrows():\n",
    "\n",
    "        if i.Language == 'nl':\n",
    "            i.emotion = i.emotion_nl\n",
    "        if i.Language == 'fr':\n",
    "            i.emotion = i.emotion_fr\n",
    "        if i.Language == 'en':\n",
    "            i.emotion = i.emotion_en\n",
    "        else:\n",
    "            '' \n",
    "            \n",
    "text_ad['text'] = text_ad['text'].map(str) + ' '+ text_ad['emotion'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index,tweet in text_ad.iterrows():\n",
    "    if tweet.Language == 'nl':\n",
    "        tweet.text = tweet.text.replace('!',' uitroepteken')\n",
    "        tweet.text = tweet.text.replace('?',' vraagteken')\n",
    "        text_ad.loc[index,:].text = tweet.text\n",
    "    else: \n",
    "        if tweet.Language == 'fr':\n",
    "            tweet.text = tweet.text.replace('!', ' point d\\'exclamation')\n",
    "            tweet.text = tweet.text.replace('?',' point d\\'interrogation')\n",
    "            text_ad.loc[index,:].text = tweet.text\n",
    "\n",
    "        else: \n",
    "            tweet.text = tweet.text.replace('!', ' exclamation mark')\n",
    "            tweet.text = tweet.text.replace('?',' question mark')\n",
    "            text_ad.loc[index,:].text = tweet.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def word2Vec(language,df):\n",
    "    dataSet = df[df.Language == language]\n",
    "    model = gensim.models.keyedvectors.Word2VecKeyedVectors\n",
    "    if language == 'en': \n",
    "        model = gensim.models.KeyedVectors.load_word2vec_format(folder + language + '.bin', binary = True)  # you can continue training with the loaded model!    \n",
    "    else: \n",
    "        model = gensim.models.Word2Vec.load(folder + language + '.bin')  # you can continue training with the loaded model!    \n",
    "    #create the appropriate format to plot the tweets in a vectorspace\n",
    "    #punctuation can be deleted now since the emotions are already converted\n",
    "    sentences = []\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    for word in dataSet.text: \n",
    "        no_punct = \"\"\n",
    "        for char in word:\n",
    "            if char not in punctuations:\n",
    "                no_punct = no_punct + char\n",
    "        sentence = no_punct.lower().split()\n",
    "        sentences.append(sentence)\n",
    "\n",
    "    #store each vector representation of a word of a tweet in a list 'vectors'\n",
    "    vectors = []\n",
    "    vocab = model.wv.vocab\n",
    "    for w in sentences:\n",
    "        vector = []\n",
    "        for i in w:\n",
    "            if i in vocab:\n",
    "                vector.append(model[i])\n",
    "\n",
    "        vectors.append(vector)\n",
    "    return vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a function to sum lists\n",
    "def sum_list(l):\n",
    "    sum = 0\n",
    "    for x in l:\n",
    "        sum += x\n",
    "    return sum    \n",
    "def TakeVectorAverage(VectorList):\n",
    "    #to take the average, we need to know how many words each tweet has\n",
    "    count = []\n",
    "    for tweet in VectorList:\n",
    "        count.append(len(tweet))\n",
    "    #sum up each list tp a total that can be divided by the count of the previous step\n",
    "    vectorsAvg = []\n",
    "    for i in range(len(count)):\n",
    "        vectorSum = []\n",
    "        vector = VectorList[i]\n",
    "        if len(vector)>1:        \n",
    "            for j in range(len(vector)):\n",
    "                vectorSum.append(vector[j])\n",
    "            total = sum_list(vectorSum)\n",
    "            average = total/count[i]\n",
    "            vectorsAvg.append(average)\n",
    "        else:\n",
    "            vectorsAvg.append(0)\n",
    "    return vectorsAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CreateAndStoreVectors(df,language):\n",
    "    tweetVectors = []\n",
    "    yVar = []\n",
    "    #filter each language subgroup\n",
    "    vectors= word2Vec(language,df)\n",
    "    Emotion = text_ad[df.Language == language].Emotion\n",
    "       \n",
    "    ###vectors = word2Vec('en',text_ad)\n",
    "    ##tweetVectors.append(vectors)\n",
    "    TweetVectorAvg = TakeVectorAverage(vectors)\n",
    "    final = pd.DataFrame({\"WordVector\": TweetVectorAvg,\"Emotion\": Emotion.tolist()})\n",
    "    \n",
    "    #we want to have all vectors in separate columns\n",
    "    dataf = pd.DataFrame()\n",
    "    dataf = pd.DataFrame(final.WordVector[0]).T\n",
    "    for i in range(1,len(final.WordVector)):\n",
    "        dataf.loc[len(dataf)] = final.WordVector.loc[i]\n",
    "    dataf['Emotion'] = final.Emotion\n",
    "    dataf.to_csv('WKDataset ' + language + '.csv', sep=';', encoding='utf-8')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hovensa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "C:\\Users\\hovensa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    }
   ],
   "source": [
    "#call all predefined functions.\n",
    "##creating the wordVectors and storing their average\n",
    "CreateAndStoreVectors(text_ad,'fr')\n",
    "CreateAndStoreVectors(text_ad, 'nl')\n",
    "CreateAndStoreVectors(text_ad, 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
